{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, loss: 2.2954413890838623, accuracy: 0.14000000059604645\n",
      "iteration: 100, loss: 1.6962486505508423, accuracy: 0.800000011920929\n",
      "iteration: 200, loss: 1.5911678075790405, accuracy: 0.8600000143051147\n",
      "iteration: 300, loss: 1.5670268535614014, accuracy: 0.9200000166893005\n",
      "iteration: 400, loss: 1.5033013820648193, accuracy: 0.9800000190734863\n",
      "iteration: 500, loss: 1.5122953653335571, accuracy: 0.9399999976158142\n",
      "iteration: 600, loss: 1.5117982625961304, accuracy: 0.9399999976158142\n",
      "iteration: 700, loss: 1.4827064275741577, accuracy: 0.9800000190734863\n",
      "iteration: 800, loss: 1.4863146543502808, accuracy: 0.9599999785423279\n",
      "iteration: 900, loss: 1.5131820440292358, accuracy: 0.9399999976158142\n",
      "iteration: 1000, loss: 1.5208368301391602, accuracy: 0.9399999976158142\n",
      "iteration: 1100, loss: 1.4832170009613037, accuracy: 0.9800000190734863\n",
      "iteration: 1200, loss: 1.4880410432815552, accuracy: 0.9800000190734863\n",
      "iteration: 1300, loss: 1.591091275215149, accuracy: 0.8799999952316284\n",
      "iteration: 1400, loss: 1.517837405204773, accuracy: 0.9599999785423279\n",
      "iteration: 1500, loss: 1.540094256401062, accuracy: 0.9200000166893005\n",
      "iteration: 1600, loss: 1.4889582395553589, accuracy: 0.9800000190734863\n",
      "iteration: 1700, loss: 1.4888083934783936, accuracy: 0.9800000190734863\n",
      "iteration: 1800, loss: 1.5811837911605835, accuracy: 0.8799999952316284\n",
      "iteration: 1900, loss: 1.4894713163375854, accuracy: 0.9599999785423279\n",
      "iteration: 2000, loss: 1.538485050201416, accuracy: 0.9200000166893005\n",
      "iteration: 2100, loss: 1.4840266704559326, accuracy: 0.9800000190734863\n",
      "iteration: 2200, loss: 1.4691519737243652, accuracy: 1.0\n",
      "iteration: 2300, loss: 1.4739571809768677, accuracy: 0.9800000190734863\n",
      "iteration: 2400, loss: 1.4986952543258667, accuracy: 0.9599999785423279\n",
      "iteration: 2500, loss: 1.5278288125991821, accuracy: 0.9399999976158142\n",
      "iteration: 2600, loss: 1.5548269748687744, accuracy: 0.8999999761581421\n",
      "iteration: 2700, loss: 1.50352144241333, accuracy: 0.9399999976158142\n",
      "iteration: 2800, loss: 1.4812413454055786, accuracy: 0.9800000190734863\n",
      "iteration: 2900, loss: 1.5017961263656616, accuracy: 0.9599999785423279\n",
      "iteration: 3000, loss: 1.5177677869796753, accuracy: 0.9399999976158142\n",
      "iteration: 3100, loss: 1.5060383081436157, accuracy: 0.9399999976158142\n",
      "iteration: 3200, loss: 1.4813323020935059, accuracy: 0.9800000190734863\n",
      "iteration: 3300, loss: 1.5133739709854126, accuracy: 0.9399999976158142\n",
      "iteration: 3400, loss: 1.461159348487854, accuracy: 1.0\n",
      "iteration: 3500, loss: 1.5020254850387573, accuracy: 0.9599999785423279\n",
      "iteration: 3600, loss: 1.4649020433425903, accuracy: 1.0\n",
      "iteration: 3700, loss: 1.54872465133667, accuracy: 0.8999999761581421\n",
      "iteration: 3800, loss: 1.4769563674926758, accuracy: 1.0\n",
      "iteration: 3900, loss: 1.500699758529663, accuracy: 0.9599999785423279\n",
      "iteration: 4000, loss: 1.5102986097335815, accuracy: 0.9399999976158142\n",
      "iteration: 4100, loss: 1.4913884401321411, accuracy: 0.9800000190734863\n",
      "iteration: 4200, loss: 1.4864012002944946, accuracy: 0.9800000190734863\n",
      "iteration: 4300, loss: 1.4719212055206299, accuracy: 1.0\n",
      "iteration: 4400, loss: 1.524905800819397, accuracy: 0.9399999976158142\n",
      "iteration: 4500, loss: 1.4799684286117554, accuracy: 0.9800000190734863\n",
      "iteration: 4600, loss: 1.4766836166381836, accuracy: 0.9800000190734863\n",
      "iteration: 4700, loss: 1.5096033811569214, accuracy: 0.9599999785423279\n",
      "iteration: 4800, loss: 1.5203007459640503, accuracy: 0.9399999976158142\n",
      "iteration: 4900, loss: 1.4611510038375854, accuracy: 1.0\n",
      "iteration: 5000, loss: 1.5076342821121216, accuracy: 0.9599999785423279\n",
      "iteration: 5100, loss: 1.4627763032913208, accuracy: 1.0\n",
      "iteration: 5200, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 5300, loss: 1.5015900135040283, accuracy: 0.9599999785423279\n",
      "iteration: 5400, loss: 1.481439471244812, accuracy: 0.9800000190734863\n",
      "iteration: 5500, loss: 1.4776568412780762, accuracy: 0.9800000190734863\n",
      "iteration: 5600, loss: 1.4615004062652588, accuracy: 1.0\n",
      "iteration: 5700, loss: 1.4709552526474, accuracy: 1.0\n",
      "iteration: 5800, loss: 1.4803799390792847, accuracy: 0.9800000190734863\n",
      "iteration: 5900, loss: 1.4815771579742432, accuracy: 0.9800000190734863\n",
      "iteration: 6000, loss: 1.5204941034317017, accuracy: 0.9399999976158142\n",
      "iteration: 6100, loss: 1.481903076171875, accuracy: 0.9800000190734863\n",
      "iteration: 6200, loss: 1.470551609992981, accuracy: 1.0\n",
      "iteration: 6300, loss: 1.5171148777008057, accuracy: 0.9399999976158142\n",
      "iteration: 6400, loss: 1.5209547281265259, accuracy: 0.9399999976158142\n",
      "iteration: 6500, loss: 1.4813002347946167, accuracy: 0.9800000190734863\n",
      "iteration: 6600, loss: 1.4810065031051636, accuracy: 0.9800000190734863\n",
      "iteration: 6700, loss: 1.4808725118637085, accuracy: 0.9800000190734863\n",
      "iteration: 6800, loss: 1.4611639976501465, accuracy: 1.0\n",
      "iteration: 6900, loss: 1.4709413051605225, accuracy: 0.9800000190734863\n",
      "iteration: 7000, loss: 1.5205951929092407, accuracy: 0.9399999976158142\n",
      "iteration: 7100, loss: 1.4667271375656128, accuracy: 1.0\n",
      "iteration: 7200, loss: 1.4778329133987427, accuracy: 0.9800000190734863\n",
      "iteration: 7300, loss: 1.4611656665802002, accuracy: 1.0\n",
      "iteration: 7400, loss: 1.474035382270813, accuracy: 0.9800000190734863\n",
      "iteration: 7500, loss: 1.4613518714904785, accuracy: 1.0\n",
      "iteration: 7600, loss: 1.5203711986541748, accuracy: 0.9399999976158142\n",
      "iteration: 7700, loss: 1.4812285900115967, accuracy: 0.9800000190734863\n",
      "iteration: 7800, loss: 1.4677245616912842, accuracy: 1.0\n",
      "iteration: 7900, loss: 1.4863684177398682, accuracy: 0.9800000190734863\n",
      "iteration: 8000, loss: 1.461159348487854, accuracy: 1.0\n",
      "iteration: 8100, loss: 1.4613935947418213, accuracy: 1.0\n",
      "iteration: 8200, loss: 1.4630001783370972, accuracy: 1.0\n",
      "iteration: 8300, loss: 1.4718492031097412, accuracy: 1.0\n",
      "iteration: 8400, loss: 1.4824198484420776, accuracy: 0.9800000190734863\n",
      "iteration: 8500, loss: 1.5011537075042725, accuracy: 0.9599999785423279\n",
      "iteration: 8600, loss: 1.5032800436019897, accuracy: 0.9599999785423279\n",
      "iteration: 8700, loss: 1.4654464721679688, accuracy: 1.0\n",
      "iteration: 8800, loss: 1.4806710481643677, accuracy: 0.9800000190734863\n",
      "iteration: 8900, loss: 1.461157202720642, accuracy: 1.0\n",
      "iteration: 9000, loss: 1.500483512878418, accuracy: 0.9599999785423279\n",
      "iteration: 9100, loss: 1.4611812829971313, accuracy: 1.0\n",
      "iteration: 9200, loss: 1.4811493158340454, accuracy: 0.9800000190734863\n",
      "iteration: 9300, loss: 1.484999418258667, accuracy: 0.9800000190734863\n",
      "iteration: 9400, loss: 1.4611616134643555, accuracy: 1.0\n",
      "iteration: 9500, loss: 1.4611549377441406, accuracy: 1.0\n",
      "iteration: 9600, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 9700, loss: 1.4612137079238892, accuracy: 1.0\n",
      "iteration: 9800, loss: 1.4750735759735107, accuracy: 0.9800000190734863\n",
      "iteration: 9900, loss: 1.4611507654190063, accuracy: 1.0\n",
      "iteration: 10000, loss: 1.4811090230941772, accuracy: 0.9800000190734863\n",
      "iteration: 10100, loss: 1.5333172082901, accuracy: 0.9200000166893005\n",
      "iteration: 10200, loss: 1.4987341165542603, accuracy: 0.9599999785423279\n",
      "iteration: 10300, loss: 1.4749670028686523, accuracy: 0.9800000190734863\n",
      "iteration: 10400, loss: 1.4611945152282715, accuracy: 1.0\n",
      "iteration: 10500, loss: 1.4611505270004272, accuracy: 1.0\n",
      "iteration: 10600, loss: 1.478369116783142, accuracy: 0.9800000190734863\n",
      "iteration: 10700, loss: 1.4818247556686401, accuracy: 0.9800000190734863\n",
      "iteration: 10800, loss: 1.4889822006225586, accuracy: 0.9800000190734863\n",
      "iteration: 10900, loss: 1.4611525535583496, accuracy: 1.0\n",
      "iteration: 11000, loss: 1.481306552886963, accuracy: 0.9800000190734863\n",
      "iteration: 11100, loss: 1.4811495542526245, accuracy: 0.9800000190734863\n",
      "iteration: 11200, loss: 1.461155652999878, accuracy: 1.0\n",
      "iteration: 11300, loss: 1.5366227626800537, accuracy: 0.9200000166893005\n",
      "iteration: 11400, loss: 1.480077862739563, accuracy: 0.9800000190734863\n",
      "iteration: 11500, loss: 1.4776272773742676, accuracy: 0.9800000190734863\n",
      "iteration: 11600, loss: 1.4779058694839478, accuracy: 0.9800000190734863\n",
      "iteration: 11700, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 11800, loss: 1.4812191724777222, accuracy: 0.9800000190734863\n",
      "iteration: 11900, loss: 1.4812469482421875, accuracy: 0.9800000190734863\n",
      "iteration: 12000, loss: 1.4611526727676392, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 12100, loss: 1.4793510437011719, accuracy: 0.9800000190734863\n",
      "iteration: 12200, loss: 1.5101782083511353, accuracy: 0.9599999785423279\n",
      "iteration: 12300, loss: 1.4759228229522705, accuracy: 0.9800000190734863\n",
      "iteration: 12400, loss: 1.4641789197921753, accuracy: 1.0\n",
      "iteration: 12500, loss: 1.4611505270004272, accuracy: 1.0\n",
      "iteration: 12600, loss: 1.4611514806747437, accuracy: 1.0\n",
      "iteration: 12700, loss: 1.461151123046875, accuracy: 1.0\n",
      "iteration: 12800, loss: 1.4811512231826782, accuracy: 0.9800000190734863\n",
      "iteration: 12900, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 13000, loss: 1.4812060594558716, accuracy: 0.9800000190734863\n",
      "iteration: 13100, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 13200, loss: 1.4611974954605103, accuracy: 1.0\n",
      "iteration: 13300, loss: 1.481153964996338, accuracy: 0.9800000190734863\n",
      "iteration: 13400, loss: 1.4612090587615967, accuracy: 1.0\n",
      "iteration: 13500, loss: 1.4811288118362427, accuracy: 0.9800000190734863\n",
      "iteration: 13600, loss: 1.4613336324691772, accuracy: 1.0\n",
      "iteration: 13700, loss: 1.4964349269866943, accuracy: 0.9599999785423279\n",
      "iteration: 13800, loss: 1.4824868440628052, accuracy: 0.9800000190734863\n",
      "iteration: 13900, loss: 1.5037658214569092, accuracy: 0.9599999785423279\n",
      "iteration: 14000, loss: 1.4611642360687256, accuracy: 1.0\n",
      "iteration: 14100, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 14200, loss: 1.461786150932312, accuracy: 1.0\n",
      "iteration: 14300, loss: 1.4611549377441406, accuracy: 1.0\n",
      "iteration: 14400, loss: 1.4611550569534302, accuracy: 1.0\n",
      "iteration: 14500, loss: 1.5211503505706787, accuracy: 0.9399999976158142\n",
      "iteration: 14600, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 14700, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 14800, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 14900, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 15000, loss: 1.4812872409820557, accuracy: 0.9800000190734863\n",
      "iteration: 15100, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 15200, loss: 1.4611504077911377, accuracy: 1.0\n",
      "iteration: 15300, loss: 1.4612051248550415, accuracy: 1.0\n",
      "iteration: 15400, loss: 1.4801688194274902, accuracy: 0.9800000190734863\n",
      "iteration: 15500, loss: 1.5187960863113403, accuracy: 0.9399999976158142\n",
      "iteration: 15600, loss: 1.4994900226593018, accuracy: 0.9599999785423279\n",
      "iteration: 15700, loss: 1.4900516271591187, accuracy: 0.9800000190734863\n",
      "iteration: 15800, loss: 1.4611750841140747, accuracy: 1.0\n",
      "iteration: 15900, loss: 1.4722470045089722, accuracy: 0.9800000190734863\n",
      "iteration: 16000, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 16100, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 16200, loss: 1.461151123046875, accuracy: 1.0\n",
      "iteration: 16300, loss: 1.4811972379684448, accuracy: 0.9800000190734863\n",
      "iteration: 16400, loss: 1.4972670078277588, accuracy: 0.9599999785423279\n",
      "iteration: 16500, loss: 1.4794399738311768, accuracy: 0.9800000190734863\n",
      "iteration: 16600, loss: 1.4792016744613647, accuracy: 0.9800000190734863\n",
      "iteration: 16700, loss: 1.5007961988449097, accuracy: 0.9599999785423279\n",
      "iteration: 16800, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 16900, loss: 1.4874087572097778, accuracy: 0.9800000190734863\n",
      "iteration: 17000, loss: 1.4611518383026123, accuracy: 1.0\n",
      "iteration: 17100, loss: 1.461212158203125, accuracy: 1.0\n",
      "iteration: 17200, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 17300, loss: 1.4805908203125, accuracy: 0.9800000190734863\n",
      "iteration: 17400, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 17500, loss: 1.4613059759140015, accuracy: 1.0\n",
      "iteration: 17600, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 17700, loss: 1.4617022275924683, accuracy: 1.0\n",
      "iteration: 17800, loss: 1.4811527729034424, accuracy: 0.9800000190734863\n",
      "iteration: 17900, loss: 1.486544132232666, accuracy: 0.9800000190734863\n",
      "iteration: 18000, loss: 1.5011584758758545, accuracy: 0.9599999785423279\n",
      "iteration: 18100, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 18200, loss: 1.4811499118804932, accuracy: 0.9800000190734863\n",
      "iteration: 18300, loss: 1.4611517190933228, accuracy: 1.0\n",
      "iteration: 18400, loss: 1.5054080486297607, accuracy: 0.9599999785423279\n",
      "iteration: 18500, loss: 1.4804490804672241, accuracy: 0.9800000190734863\n",
      "iteration: 18600, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 18700, loss: 1.4821912050247192, accuracy: 0.9800000190734863\n",
      "iteration: 18800, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 18900, loss: 1.4811501502990723, accuracy: 0.9800000190734863\n",
      "iteration: 19000, loss: 1.461197853088379, accuracy: 1.0\n",
      "iteration: 19100, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 19200, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 19300, loss: 1.4612196683883667, accuracy: 1.0\n",
      "iteration: 19400, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 19500, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 19600, loss: 1.4622758626937866, accuracy: 1.0\n",
      "iteration: 19700, loss: 1.4611501693725586, accuracy: 1.0\n",
      "iteration: 19800, loss: 1.4611504077911377, accuracy: 1.0\n",
      "iteration: 19900, loss: 1.4611501693725586, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "inp_units = 784\n",
    "hidden1_units = 1000\n",
    "hidden2_units = 100\n",
    "output_units = 10\n",
    "\n",
    "image_placeholder = tf.placeholder(tf.float32, shape=[None, inp_units])\n",
    "label_placeholder = tf.placeholder(tf.float32, shape=[None, output_units])\n",
    "\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights_h1 = tf.Variable(tf.truncated_normal([inp_units, hidden1_units], stddev=1/tf.sqrt(inp_units/2)), name=\"weights\")\n",
    "    bias_h1 = tf.Variable(tf.zeros([hidden1_units]), name=\"biases\")\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights_h2 = tf.Variable(tf.truncated_normal([hidden1_units, hidden2_units], stddev=1/tf.sqrt(hidden1_units/2)), name=\"weights\")\n",
    "    bias_h2 = tf.Variable(tf.zeros([hidden2_units]), name=\"biases\")\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    weights_out = tf.Variable(tf.truncated_normal([hidden2_units, output_units], stddev=1/tf.sqrt(hidden2_units/2)), name=\"weights\")\n",
    "    bias_out = tf.Variable(tf.zeros([output_units]), name=\"biases\")\n",
    "\n",
    "hidden1 = tf.nn.relu(tf.matmul(image_placeholder, weights_h1) + bias_h1)\n",
    "hidden2 = tf.nn.relu(tf.matmul(hidden1, weights_h2) + bias_h2)\n",
    "\n",
    "logits = tf.nn.softmax(tf.matmul(hidden2, weights_out) + bias_out)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label_placeholder, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(label_placeholder, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    loss, acc, _ = sess.run([cross_entropy, accuracy, train_step], feed_dict={image_placeholder: batch[0], label_placeholder: batch[1]})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"iteration: {0}, loss: {1}, accuracy: {2}\".format(i, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy on MNIST data [0.97280002]\n"
     ]
    }
   ],
   "source": [
    "test_acc = sess.run([accuracy],feed_dict={image_placeholder: mnist.test.images, label_placeholder: mnist.test.labels})\n",
    "print(\"test accuracy on MNIST data {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
